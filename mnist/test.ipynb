{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hodooai\\anaconda3\\envs\\mnist\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # CPU or GPU\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('./', train=True, download=True) # get train dataset\n",
    "test_dataset = torchvision.datasets.MNIST('./', train=False) # get test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  torch.Size([60000, 28, 28])\n",
      "y_train shape :  torch.Size([60000])\n",
      "x_test  shape :  torch.Size([10000, 28, 28])\n",
      "y_test  shape :  torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hodooai\\anaconda3\\envs\\mnist\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "c:\\Users\\hodooai\\anaconda3\\envs\\mnist\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "c:\\Users\\hodooai\\anaconda3\\envs\\mnist\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\Users\\hodooai\\anaconda3\\envs\\mnist\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "x_train_orig = train_dataset.train_data  #train image, [Type image, width, height]\n",
    "y_train_orig = train_dataset.train_labels #train labels, [Type labels]\n",
    "x_test_orig = test_dataset.test_data \n",
    "y_test_orig = test_dataset.test_labels\n",
    "print('x_train shape : ', x_train_orig.shape) \n",
    "print('y_train shape : ', y_train_orig.shape)\n",
    "print('x_test  shape : ', x_test_orig.shape)\n",
    "print('y_test  shape : ', y_test_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  torch.Size([50000, 28, 28])\n",
      "y_train shape :  torch.Size([50000])\n",
      "x_train shape :  torch.Size([10000, 28, 28])\n",
      "y_train shape :  torch.Size([10000])\n",
      "x_test  shape :  torch.Size([10000, 28, 28])\n",
      "y_test  shape :  torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#normalization , 픽셀값 255 -> 0과 1사이로 값을 줄이기 위해서  255로 나눔\n",
    "x_train = (x_train_orig[10000:] / 255.).to(device=device) # 학습자체에 쓰인 데이터, 수학 비교 -> 문제 풀이 존나 학습 // #To device는 GPU로 보냄\n",
    "y_train = y_train_orig[10000:].to(device=device)\n",
    "x_val = (x_train_orig[:10000] / 255.).to(device=device) # 학습과정 안에서 평가를 위해 쓰인 데이터 //  수학 비교 -> 존나 학습한거 새 문제 풀어보기 및 정답 확인\n",
    "y_val = y_train_orig[:10000].to(device=device)\n",
    "x_test = x_test_orig / 255. # 학습 후 최종 평가\n",
    "y_test = y_test_orig\n",
    " \n",
    "print('x_train shape : ', x_train.shape)\n",
    "print('y_train shape : ', y_train.shape)\n",
    "print('x_train shape : ', x_val.shape)\n",
    "print('x_type : ', type(x_val))\n",
    "print('y_train shape : ', y_val.shape)\n",
    "   \n",
    "print('x_test  shape : ', x_test.shape)\n",
    "print('y_test  shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = torch.utils.data.TensorDataset(x_train, y_train) #데이터셋\n",
    "train_loader = torch.utils.data.DataLoader(trainingset, batch_size=32, shuffle=True) # 전체 이미지를 분할하여 불러오는 로더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.79616117477417 sec - loss : 0.18525858223438263 / acc : 95.29000091552734\n",
      "5.564436912536621 sec - loss : 0.14928655326366425 / acc : 96.31999969482422\n",
      "6.279510259628296 sec - loss : 0.11206672340631485 / acc : 97.18000030517578\n",
      "6.180745601654053 sec - loss : 0.11277177929878235 / acc : 97.18000030517578\n",
      "5.5314226150512695 sec - loss : 0.1400911957025528 / acc : 96.93000030517578\n",
      "5.577991247177124 sec - loss : 0.10267786681652069 / acc : 97.47999572753906\n",
      "5.78205132484436 sec - loss : 0.11861927807331085 / acc : 97.5999984741211\n",
      "5.897591829299927 sec - loss : 0.11700544506311417 / acc : 97.39999389648438\n",
      "6.005919694900513 sec - loss : 0.11018732935190201 / acc : 97.54999542236328\n",
      "5.7625977993011475 sec - loss : 0.1278049498796463 / acc : 97.77999877929688\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 256) # 784란 28(width) x 28(height)\n",
    "        self.fc2 = torch.nn.Linear(256, 256)\n",
    "        self.fc3 = torch.nn.Linear(256, 256)\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.fc5 = torch.nn.Linear(128, 128)\n",
    "        self.fc6 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x): # fully connected\n",
    "        x = x.view(-1, 784) #-1 = 아무거나, 784 = 28 x 28 // 1 784, 2 392 ... 이런너낌스\n",
    "        x = torch.nn.functional.relu(self.fc1(x)) #relu +신호는 그대로 -신호는 차단\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.relu(self.fc3(x))\n",
    "        x = torch.nn.functional.relu(self.fc4(x))\n",
    "        x = torch.nn.functional.relu(self.fc5(x))\n",
    "        x = torch.nn.functional.dropout(x, training=self.training) #dropout : layer를 랜덤하게 삭제해줌\n",
    "        x = self.fc6(x) \n",
    "        return x\n",
    "m1 = Net()\n",
    "m1.cuda() # GPU로 전송\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # criterion 목적함수\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=0.001) #Adam이라는 최적화 기법\n",
    "\n",
    "# 배치 -> 이미지를 나눠 학습\n",
    "# epoch -> 전체이미지 반복학습\n",
    "for epoch in range(10):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        #xb, yb = torch.autograd.Variable(xb), torch.autograd.Variable(yb)\n",
    "\n",
    "        pred = m1(xb) #pred = prediction\n",
    "        loss = criterion(pred, yb)\n",
    "\n",
    "        loss.backward() #바뀔 값들을 연산\n",
    "        optimizer.step() # 실제 바뀐값을 적용\n",
    "        optimizer.zero_grad() # ?검색해보셈 \n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    with torch.no_grad(): #1에폭당 한번 평가 여기선 val데이터를 사용해야함 왜냐면 학습한걸로 평가하면 ㅄ이기때문이다\n",
    "        pred = m1(x_val)\n",
    "     \n",
    "        acc = pred.data.max(1)[1].eq(y_val.data).sum()/len(x_val) * 100\n",
    "        loss = criterion(pred, y_val)\n",
    "    print(f\"{time.time() -  start} sec - loss : {loss} / acc : {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.11388404667377472 / acc : 97.85999298095703\n"
     ]
    }
   ],
   "source": [
    "pred = m1(x_test.to(device=device))\n",
    "acc = pred.data.max(1)[1].eq(y_test.to(device=device).data).sum()/len(x_test) * 100\n",
    "loss = criterion(pred, y_test.to(device=device))\n",
    "print(f\"loss : {loss} / acc : {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 16, 2, 1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = CNN_Model()\n",
    "m2.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr= 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29483699798584 sec - loss : 0.10558062791824341 / acc : 96.8219985961914\n",
      "3.813631534576416 sec - loss : 0.06708876043558121 / acc : 97.94599914550781\n",
      "3.867177963256836 sec - loss : 0.05351058021187782 / acc : 98.3899917602539\n",
      "3.916050910949707 sec - loss : 0.04785405099391937 / acc : 98.45800018310547\n",
      "3.9998743534088135 sec - loss : 0.04052738472819328 / acc : 98.74800109863281\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for xb, yb in train_loader:        \n",
    "        pred = m2(xb)\n",
    "        loss = criterion(pred, yb.long())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = m2(x_train)\n",
    "        acc = pred.data.max(1)[1].eq(y_train.data).sum()/len(x_train) * 100\n",
    "        loss = criterion(pred, y_train)\n",
    "    print(f\"{time.time() - start} sec - loss : {loss} / acc : {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.053827498108148575 / acc : 98.28999328613281\n"
     ]
    }
   ],
   "source": [
    "pred = m2(x_test.to(device=device))\n",
    "acc = pred.data.max(1)[1].eq(y_test.to(device=device).data).sum()/len(x_test) * 100\n",
    "loss = criterion(pred, y_test.to(device=device))\n",
    "print(f\"loss : {loss} / acc : {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번 테스트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
